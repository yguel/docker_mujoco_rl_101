{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c41435f",
   "metadata": {},
   "source": [
    "\n",
    "# Inferring an RL API from a **Black-Box** MuJoCo Environment\n",
    "\n",
    "**Goal:** Using only the **MuJoCo Python API**, you will *infer* a standard RL interface:\n",
    "- `reset()` → returns an initial **state** and **info**\n",
    "- `step(action)` → returns **next_state, reward, terminated, truncated, info**\n",
    "- Distinguish **state vs next_state**, log a **trajectory**, and understand **`terminated` vs `truncated`**.\n",
    "\n",
    "> Treat the environment as a **sealed box**. You can inspect shapes, bounds, samples, and results,\n",
    "> but you should not rely on its internal implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec5c1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.3\n",
      "MuJoCo version: 3.3.6\n",
      "Numpy: 1.26.4\n",
      "Matplotlib: 3.8.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Setup ---\n",
    "# If you don't have mujoco installed, uncomment:\n",
    "# !pip install -U mujoco matplotlib numpy pandas\n",
    "\n",
    "import os, sys, math, random, tempfile, numpy as np #, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mujoco  # official MuJoCo Python bindings\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"MuJoCo version:\", mujoco.__version__)\n",
    "print(\"Numpy:\", np.__version__)\n",
    "# print(\"Pandas:\", pd.__version__)\n",
    "print(\"Matplotlib:\", plt.matplotlib.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a623f6",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Our **black-box** MuJoCo world\n",
    "\n",
    "We embed a tiny model: a 1D **cart** sliding along x with a single motor actuator.\n",
    "You won’t need to understand the XML; it exists so we can interact via MuJoCo only.\n",
    "\n",
    "> In a real assignment you could swap in any MuJoCo XML you like. The *API* you infer stays the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd720f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model XML written to: /tmp/mujoco_blackbox_p_yvxx6a/cart1d.xml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write the embedded XML to a temp file so MuJoCo can load it.\n",
    "import tempfile, pathlib\n",
    "xml_text = r\"\"\"<mujoco model=\"cart1d\">\n",
    "  <compiler angle=\"degree\" autolimits=\"true\"/>\n",
    "  <option timestep=\"0.01\" gravity=\"0 0 -9.81\"/>\n",
    "  <default>\n",
    "    <geom size=\"0.05\" rgba=\"0.7 0.7 0.7 1\"/>\n",
    "  </default>\n",
    "\n",
    "  <worldbody>\n",
    "    <geom name=\"ground\" type=\"plane\" size=\"10 10 0.1\" rgba=\"0.2 0.2 0.2 1\" pos=\"0 0 0\"/>\n",
    "    <body name=\"rail\" pos=\"0 0 0.1\">\n",
    "      <geom type=\"capsule\" fromto=\"-3 0 0.1 3 0 0.1\" size=\"0.02\" rgba=\"0.5 0.5 0.5 1\"/>\n",
    "    </body>\n",
    "    <body name=\"cart\" pos=\"0 0 0.2\">\n",
    "      <joint name=\"x\" type=\"slide\" axis=\"1 0 0\" limited=\"true\" range=\"-3 3\" damping=\"0.5\"/>\n",
    "      <geom type=\"box\" size=\"0.1 0.05 0.05\" rgba=\"0.1 0.4 0.8 1\"/>\n",
    "    </body>\n",
    "  </worldbody>\n",
    "\n",
    "  <actuator>\n",
    "    <motor name=\"x_motor\" joint=\"x\" gear=\"1\" ctrllimited=\"true\" ctrlrange=\"-3 3\"/>\n",
    "  </actuator>\n",
    "</mujoco>\"\"\"\n",
    "tmp_dir = tempfile.mkdtemp(prefix=\"mujoco_blackbox_\")\n",
    "xml_path = str(pathlib.Path(tmp_dir) / \"cart1d.xml\")\n",
    "with open(xml_path, \"w\") as f:\n",
    "    f.write(xml_text)\n",
    "print(\"Model XML written to:\", xml_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735cd23",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Black-box wrapper (opaque internals)\n",
    "\n",
    "The class below defines `reset()` and `step()` **directly** on top of MuJoCo physics.\n",
    "You should focus on using its API, not its internal rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66f10a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import mujoco\n",
    "\n",
    "class MuJoCoBlackBoxEnv:\n",
    "    def __init__(self, xml_path, frame_skip=5, max_episode_steps=200):\n",
    "        self.model = mujoco.MjModel.from_xml_path(xml_path)\n",
    "        self.data = mujoco.MjData(self.model)\n",
    "        self.rng = np.random.default_rng()\n",
    "        self.frame_skip = int(frame_skip)\n",
    "        self.max_episode_steps = int(max_episode_steps)\n",
    "        self._t = 0\n",
    "\n",
    "        self.nq = self.model.nq\n",
    "        self.nv = self.model.nv\n",
    "        self.nu = self.model.nu\n",
    "\n",
    "        if self.model.nu > 0 and self.model.actuator_ctrllimited.any():\n",
    "            low = self.model.actuator_ctrlrange[:,0]\n",
    "            high = self.model.actuator_ctrlrange[:,1]\n",
    "        else:\n",
    "            low = -np.ones(self.model.nu, dtype=float)\n",
    "            high =  np.ones(self.model.nu, dtype=float)\n",
    "\n",
    "        self.action_low  = low.astype(float)\n",
    "        self.action_high = high.astype(float)\n",
    "\n",
    "        self.state_shape = (self.nq + self.nv,)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        if seed is not None:\n",
    "            self.rng = np.random.default_rng(seed)\n",
    "\n",
    "        mujoco.mj_resetData(self.model, self.data)\n",
    "        self._t = 0\n",
    "\n",
    "        qpos = 0.01 * self.rng.standard_normal(self.nq)\n",
    "        qvel = 0.01 * self.rng.standard_normal(self.nv)\n",
    "\n",
    "        if isinstance(options, dict):\n",
    "            if \"qpos\" in options and np.size(options[\"qpos\"]) == self.nq:\n",
    "                qpos = np.asarray(options[\"qpos\"], dtype=float)\n",
    "            if \"qvel\" in options and np.size(options[\"qvel\"]) == self.nv:\n",
    "                qvel = np.asarray(options[\"qvel\"], dtype=float)\n",
    "\n",
    "        self.data.qpos[:] = qpos\n",
    "        self.data.qvel[:] = qvel\n",
    "        self.data.ctrl[:] = 0.0\n",
    "\n",
    "        mujoco.mj_forward(self.model, self.data)\n",
    "\n",
    "        return self._get_state(), {\"t\": self._t}\n",
    "\n",
    "    def step(self, action):\n",
    "        a = np.asarray(action, dtype=float).reshape(self.nu)\n",
    "        a = np.clip(a, self.action_low, self.action_high)\n",
    "        self.data.ctrl[:] = a\n",
    "\n",
    "        for _ in range(self.frame_skip):\n",
    "            mujoco.mj_step(self.model, self.data)\n",
    "\n",
    "        self._t += 1\n",
    "\n",
    "        reward = self._compute_reward(a)\n",
    "        terminated = self._check_terminated()\n",
    "        truncated = self._t >= self.max_episode_steps\n",
    "\n",
    "        info = {\"t\": self._t}\n",
    "        return self._get_state(), float(reward), bool(terminated), bool(truncated), info\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def sample_action(self):\n",
    "        u = self.rng.uniform(0.0, 1.0, size=self.nu)\n",
    "        return self.action_low + u * (self.action_high - self.action_low)\n",
    "\n",
    "    def action_bounds(self):\n",
    "        return self.action_low.copy(), self.action_high.copy()\n",
    "\n",
    "    def _get_state(self):\n",
    "        return np.concatenate([self.data.qpos, self.data.qvel], dtype=float)\n",
    "\n",
    "    def _compute_reward(self, action):\n",
    "        x = float(self.data.qpos[0]) if self.nq > 0 else 0.0\n",
    "        ctrl_pen = 0.01 * float(np.dot(action, action))\n",
    "        return -(x*x) - ctrl_pen\n",
    "\n",
    "    def _check_terminated(self):\n",
    "        x = float(self.data.qpos[0]) if self.nq > 0 else 0.0\n",
    "        return abs(x) > 2.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73862ea7",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Instantiate and probe shapes/bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3d5dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state shape: (2,) dtype: float64\n",
      "Action bounds: [-3.] [3.]\n",
      "Info keys: ['t']\n",
      "Sample state (first 4): [-0.00989121 -0.00367787]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = MuJoCoBlackBoxEnv(xml_path, frame_skip=5, max_episode_steps=100)\n",
    "\n",
    "state, info = env.reset(seed=123)\n",
    "print(\"Initial state shape:\", state.shape, \"dtype:\", state.dtype)\n",
    "act_low, act_high = env.action_bounds()\n",
    "print(\"Action bounds:\", act_low, act_high)\n",
    "print(\"Info keys:\", list(info.keys()))\n",
    "print(\"Sample state (first 4):\", state[:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3677ec39",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Single-step probe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4da5b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action shape: (1,)\n",
      "Next state shape: (2,)\n",
      "Reward: -0.028249524384621895 <class 'float'>\n",
      "terminated: False truncated: False\n",
      "Info: {'t': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "action = env.sample_action()\n",
    "next_state, reward, terminated, truncated, info = env.step(action)\n",
    "print(\"Action shape:\", action.shape)\n",
    "print(\"Next state shape:\", next_state.shape)\n",
    "print(\"Reward:\", reward, type(reward))\n",
    "print(\"terminated:\", terminated, \"truncated:\", truncated)\n",
    "print(\"Info:\", info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa825c",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Reset, seeding, and options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5db0ebc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed reproducibility (7 vs 7): True\n",
      "Different seeds (7 vs 8): False\n",
      "Custom reset accepted; state[0] (x) ~ 2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s1, _ = env.reset(seed=7)\n",
    "s2, _ = env.reset(seed=7)\n",
    "s3, _ = env.reset(seed=8)\n",
    "\n",
    "print(\"Seed reproducibility (7 vs 7):\", np.allclose(s1, s2))\n",
    "print(\"Different seeds (7 vs 8):\", np.allclose(s1, s3))\n",
    "\n",
    "custom = {\"qpos\": np.array([2.0]), \"qvel\": np.array([0.0])}\n",
    "s_custom, info_custom = env.reset(options=custom)\n",
    "print(\"Custom reset accepted; state[0] (x) ~\", float(s_custom[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646faa3",
   "metadata": {},
   "source": [
    "\n",
    "## 6) `terminated` vs `truncated`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b1f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran a silent random episode.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_one_episode_random(env, verbose=True):\n",
    "    s, info = env.reset(seed=42)\n",
    "    total_reward = 0.0\n",
    "    t = 0\n",
    "    while True:\n",
    "        a = env.sample_action()\n",
    "        s_next, r, terminated, truncated, info = env.step(a)\n",
    "        total_reward += r\n",
    "        t += 1\n",
    "        if verbose:\n",
    "            print(f\"t={t:<3} r={r: .3f} term={terminated} trunc={truncated}\")\n",
    "        if terminated or truncated:\n",
    "            reason = \"terminated\" if terminated else \"truncated\"\n",
    "            if verbose:\n",
    "                print(f\"Episode ended by **{reason}** at t={t}; total_reward={total_reward:.2f}\")\n",
    "            break\n",
    "        s = s_next\n",
    "    return t, total_reward\n",
    "\n",
    "_ = run_one_episode_random(env, verbose=False)\n",
    "print(\"Ran a silent random episode.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194b99f3",
   "metadata": {},
   "source": [
    "\n",
    "### Force truncation with a short max length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb0ef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=1   r=-0.046 term=False trunc=False\n",
      "t=2   r=-0.014 term=False trunc=False\n",
      "t=3   r=-0.059 term=False trunc=False\n",
      "t=4   r=-0.081 term=False trunc=False\n",
      "t=5   r=-0.025 term=False trunc=False\n",
      "t=6   r=-0.029 term=False trunc=False\n",
      "t=7   r=-0.050 term=False trunc=False\n",
      "t=8   r=-0.001 term=False trunc=False\n",
      "t=9   r=-0.006 term=False trunc=False\n",
      "t=10  r=-0.066 term=False trunc=True\n",
      "Episode ended by **truncated** at t=10; total_reward=-0.38\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env_short = MuJoCoBlackBoxEnv(xml_path, frame_skip=5, max_episode_steps=10)\n",
    "steps, total_reward = run_one_episode_random(env_short, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a5536f",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Trajectory logging and alternating (s0, a0, s1, a1, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d0d01a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m         t += \u001b[32m1\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m traj_alt, pd.DataFrame(rows)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m traj_alt, traj_df = \u001b[43mrollout_random\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m123\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAlternating list length = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(traj_alt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (expect 2*T + 1)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(traj_df.head())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mrollout_random\u001b[39m\u001b[34m(env, max_steps, seed)\u001b[39m\n\u001b[32m     20\u001b[39m     s = s_next\n\u001b[32m     21\u001b[39m     t += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m traj_alt, \u001b[43mpd\u001b[49m.DataFrame(rows)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def rollout_random(env, max_steps=200, seed=0):\n",
    "    s, info = env.reset(seed=seed)\n",
    "    traj_alt = [np.copy(s)]\n",
    "    rows = []\n",
    "    terminated = truncated = False\n",
    "    t = 0\n",
    "    while not (terminated or truncated) and t < max_steps:\n",
    "        a = env.sample_action()\n",
    "        s_next, r, terminated, truncated, info = env.step(a)\n",
    "        traj_alt.append(np.copy(a))\n",
    "        traj_alt.append(np.copy(s_next))\n",
    "        rows.append({\n",
    "            \"t\": t,\n",
    "            \"reward\": float(r),\n",
    "            \"terminated\": bool(terminated),\n",
    "            \"truncated\": bool(truncated),\n",
    "            \"s0\": float(s[0]) if s.size > 0 else np.nan,\n",
    "            \"a0\": float(a[0]) if a.size > 0 else np.nan,\n",
    "        })\n",
    "        s = s_next\n",
    "        t += 1\n",
    "    return traj_alt, pd.DataFrame(rows)\n",
    "\n",
    "traj_alt, traj_df = rollout_random(env, max_steps=100, seed=123)\n",
    "print(f\"Alternating list length = {len(traj_alt)} (expect 2*T + 1)\")\n",
    "print(traj_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25241ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from caas_jupyter_tools import display_dataframe_to_user\n",
    "    display_dataframe_to_user(\"Trajectory (first components)\", traj_df)\n",
    "except Exception:\n",
    "    traj_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de854da",
   "metadata": {},
   "source": [
    "\n",
    "### Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d261e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(traj_df[\"t\"], traj_df[\"reward\"])\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"reward\")\n",
    "plt.title(\"Reward per step\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1712d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(traj_df[\"t\"], traj_df[\"s0\"])\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"state[0] (x)\")\n",
    "plt.title(\"First state component over time\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c2ee5",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Summary of the inferred API\n",
    "\n",
    "- `state, info = env.reset(seed=..., options=...)`\n",
    "- `next_state, reward, terminated, truncated, info = env.step(action)`\n",
    "- `done = terminated or truncated`\n",
    "- State shape `(nq+nv,)`, action shape `(nu,)` with bounds from MuJoCo control ranges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00df0b",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Exercises\n",
    "1. Sample 1,000 actions and verify they respect the bounds.\n",
    "2. With a fixed seed and a fixed action sequence, show identical first *k* steps across runs.\n",
    "3. Increase `max_episode_steps` and intentionally cause termination by pushing beyond \\|x\\|>2.5.\n",
    "4. Use `options` to start near the boundary; compare episode lengths.\n",
    "5. Swap `sample_action()` for a proportional controller toward x=0; compare rewards.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
